{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d834bb-266f-496c-946a-11bac1dbf314",
   "metadata": {},
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1163c2-9096-49a0-bd5b-0b2a2d07f638",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c339434b-baf8-412c-82d9-3d9c2180a165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Needed for training\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "# Models\n",
    "from models_part1 import FinalClassifier , MNISTAutoencoder, CIFAR10Autoencoder\n",
    "from models_part2 import MNISTClassifyingAutoencoder,CIFAR10ClassifyingAutoencoder\n",
    "from models_part3 import NTXentLoss,MnistSimCLR,Cifar10SimCLR\n",
    "from models_testing import  plot_accuracies,plot_losses,test_classifier,test_classifyingAutoEncoder\n",
    "from models_eval import Accuracy_report,Reconstruction_report,showcase_reconstruction, showcase_interpolation,plot_all_tsne_plots\n",
    "import data_loading\n",
    "from models_training import train_all_models\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb04dd-aeed-4ae7-b860-d075e6ed38e1",
   "metadata": {},
   "source": [
    "### Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5482b249-026e-4e00-9e38-9b551f9ca44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9e50e-fdfc-43ca-b7ec-5b4540840cc4",
   "metadata": {},
   "source": [
    "## Accuracy Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772a77a-a6f4-4bf0-8f88-316ff0457c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing : ** Part ** 1, mnist model ...\n",
      "MNIST dataset downloaded successfully!\n",
      "Train size: 50000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Computing train accuracy ...\n",
      "Test Accuracy: 99.99%\n",
      "------------------------------\n",
      "Computing val accuracy ...\n",
      "Test Accuracy: 98.38%\n",
      "------------------------------\n",
      "Computing test accuracy ...\n",
      "Test Accuracy: 98.45%\n",
      "------------------------------\n",
      "Testing : ** Part ** 1, cifar model ...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR-10 dataset downloaded successfully!\n",
      "Train size: 40000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Computing train accuracy ...\n",
      "Test Accuracy: 82.73%\n",
      "------------------------------\n",
      "Computing val accuracy ...\n",
      "Test Accuracy: 59.63%\n",
      "------------------------------\n",
      "Computing test accuracy ...\n",
      "Test Accuracy: 58.21%\n",
      "------------------------------\n",
      "Testing : ** Part ** 2, mnist model ...\n",
      "MNIST dataset downloaded successfully!\n",
      "Train size: 50000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Computing train accuracy ...\n"
     ]
    }
   ],
   "source": [
    "Accuracy_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35675b0e-87a5-4c78-85e4-4d3e5a616bb1",
   "metadata": {},
   "source": [
    "## MAE Reconstruction Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6175b5a-9301-428c-ae9d-2ebe0263cada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca7bba8c-3004-40be-8196-fff3ff6baa43",
   "metadata": {},
   "source": [
    "## Showcasing reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302ba90-5f36-43f5-9893-f108d33c0960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ce99ee1-60c9-4a59-ae9a-13ddc1d1e819",
   "metadata": {},
   "source": [
    "## Showcasing Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b3306-0c2b-4591-9633-28d0e20b0b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7e7b98-97f9-4ce7-9028-1eef6aba1d5c",
   "metadata": {},
   "source": [
    "## tSNE plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef19299-edc2-4825-a9de-f95fd54dd1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fa97a6c-8623-4961-bcc0-83198b891a21",
   "metadata": {},
   "source": [
    "## Training all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaefbb72-87fa-48e5-9d41-d22b7537b8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 1 ,Training mnist model ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "MNIST dataset downloaded successfully!\n",
      "Train size: 50000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Epoch [1/40], Time: 19.53s, Train Loss: 0.1321, Val Loss: 0.0356, LR: 0.0010000\n",
      "Epoch [2/40], Time: 10.86s, Train Loss: 0.0426, Val Loss: 0.0312, LR: 0.0010000\n",
      "Epoch [3/40], Time: 10.81s, Train Loss: 0.0399, Val Loss: 0.0291, LR: 0.0010000\n",
      "Epoch [4/40], Time: 10.99s, Train Loss: 0.0381, Val Loss: 0.0279, LR: 0.0010000\n",
      "Epoch [5/40], Time: 10.85s, Train Loss: 0.0371, Val Loss: 0.0271, LR: 0.0010000\n",
      "Epoch [6/40], Time: 10.82s, Train Loss: 0.0362, Val Loss: 0.0262, LR: 0.0010000\n",
      "Epoch [7/40], Time: 10.81s, Train Loss: 0.0355, Val Loss: 0.0256, LR: 0.0010000\n",
      "Epoch [8/40], Time: 10.82s, Train Loss: 0.0348, Val Loss: 0.0252, LR: 0.0010000\n",
      "Epoch [9/40], Time: 10.73s, Train Loss: 0.0344, Val Loss: 0.0247, LR: 0.0010000\n",
      "Epoch [10/40], Time: 10.75s, Train Loss: 0.0339, Val Loss: 0.0241, LR: 0.0010000\n",
      "Epoch [11/40], Time: 10.84s, Train Loss: 0.0336, Val Loss: 0.0237, LR: 0.0010000\n",
      "Epoch [12/40], Time: 10.87s, Train Loss: 0.0332, Val Loss: 0.0234, LR: 0.0010000\n",
      "Epoch [13/40], Time: 11.28s, Train Loss: 0.0330, Val Loss: 0.0232, LR: 0.0010000\n",
      "Epoch [14/40], Time: 11.15s, Train Loss: 0.0328, Val Loss: 0.0229, LR: 0.0010000\n",
      "Epoch [15/40], Time: 11.15s, Train Loss: 0.0324, Val Loss: 0.0229, LR: 0.0010000\n",
      "Epoch [16/40], Time: 11.04s, Train Loss: 0.0323, Val Loss: 0.0226, LR: 0.0010000\n",
      "Epoch [17/40], Time: 11.27s, Train Loss: 0.0320, Val Loss: 0.0229, LR: 0.0010000\n",
      "Epoch [18/40], Time: 11.45s, Train Loss: 0.0318, Val Loss: 0.0224, LR: 0.0010000\n",
      "Epoch [19/40], Time: 11.32s, Train Loss: 0.0316, Val Loss: 0.0222, LR: 0.0010000\n",
      "Epoch [20/40], Time: 11.20s, Train Loss: 0.0315, Val Loss: 0.0220, LR: 0.0010000\n",
      "Epoch [21/40], Time: 11.36s, Train Loss: 0.0314, Val Loss: 0.0220, LR: 0.0010000\n",
      "Epoch [22/40], Time: 11.27s, Train Loss: 0.0312, Val Loss: 0.0218, LR: 0.0010000\n",
      "Epoch [23/40], Time: 11.19s, Train Loss: 0.0311, Val Loss: 0.0216, LR: 0.0010000\n",
      "Epoch [24/40], Time: 11.49s, Train Loss: 0.0310, Val Loss: 0.0218, LR: 0.0010000\n",
      "Epoch [25/40], Time: 12.19s, Train Loss: 0.0309, Val Loss: 0.0216, LR: 0.0010000\n",
      "Epoch [26/40], Time: 11.15s, Train Loss: 0.0308, Val Loss: 0.0216, LR: 0.0010000\n",
      "Epoch [27/40], Time: 11.19s, Train Loss: 0.0307, Val Loss: 0.0213, LR: 0.0010000\n",
      "Epoch [28/40], Time: 11.30s, Train Loss: 0.0305, Val Loss: 0.0212, LR: 0.0010000\n",
      "Epoch [29/40], Time: 11.35s, Train Loss: 0.0304, Val Loss: 0.0214, LR: 0.0010000\n",
      "Epoch [30/40], Time: 11.28s, Train Loss: 0.0304, Val Loss: 0.0212, LR: 0.0010000\n",
      "Epoch [31/40], Time: 11.39s, Train Loss: 0.0303, Val Loss: 0.0212, LR: 0.0010000\n",
      "Epoch [32/40], Time: 10.96s, Train Loss: 0.0302, Val Loss: 0.0211, LR: 0.0010000\n",
      "Epoch [33/40], Time: 11.21s, Train Loss: 0.0301, Val Loss: 0.0211, LR: 0.0010000\n",
      "Epoch [34/40], Time: 11.36s, Train Loss: 0.0301, Val Loss: 0.0208, LR: 0.0010000\n",
      "Epoch [35/40], Time: 11.18s, Train Loss: 0.0301, Val Loss: 0.0210, LR: 0.0010000\n",
      "Epoch [36/40], Time: 11.13s, Train Loss: 0.0299, Val Loss: 0.0209, LR: 0.0010000\n",
      "Epoch [37/40], Time: 11.20s, Train Loss: 0.0299, Val Loss: 0.0207, LR: 0.0010000\n",
      "Epoch [38/40], Time: 11.26s, Train Loss: 0.0298, Val Loss: 0.0207, LR: 0.0010000\n",
      "Epoch [39/40], Time: 11.19s, Train Loss: 0.0298, Val Loss: 0.0209, LR: 0.0010000\n",
      "Epoch [40/40], Time: 11.09s, Train Loss: 0.0297, Val Loss: 0.0207, LR: 0.0010000\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 1 , Training classifier for the mnist encoder\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Epoch [1/30], Time: 12.86s, Train Loss: 0.2752, Train Accuracy: 92.05%, Val Accuracy: 96.33%, LR: 0.001000\n",
      "Epoch [2/30], Time: 12.92s, Train Loss: 0.1254, Train Accuracy: 96.23%, Val Accuracy: 97.04%, LR: 0.001000\n",
      "Epoch [3/30], Time: 12.56s, Train Loss: 0.0913, Train Accuracy: 97.13%, Val Accuracy: 97.23%, LR: 0.001000\n",
      "Epoch [4/30], Time: 12.73s, Train Loss: 0.0714, Train Accuracy: 97.71%, Val Accuracy: 97.38%, LR: 0.001000\n",
      "Epoch [5/30], Time: 12.81s, Train Loss: 0.0643, Train Accuracy: 97.97%, Val Accuracy: 97.57%, LR: 0.001000\n",
      "Epoch [6/30], Time: 12.65s, Train Loss: 0.0541, Train Accuracy: 98.20%, Val Accuracy: 97.94%, LR: 0.001000\n",
      "Epoch [7/30], Time: 12.65s, Train Loss: 0.0479, Train Accuracy: 98.50%, Val Accuracy: 97.73%, LR: 0.001000\n",
      "Epoch [8/30], Time: 12.71s, Train Loss: 0.0459, Train Accuracy: 98.44%, Val Accuracy: 97.97%, LR: 0.001000\n",
      "Epoch [9/30], Time: 12.65s, Train Loss: 0.0434, Train Accuracy: 98.50%, Val Accuracy: 97.82%, LR: 0.001000\n",
      "Epoch [10/30], Time: 12.67s, Train Loss: 0.0395, Train Accuracy: 98.72%, Val Accuracy: 97.78%, LR: 0.000125\n",
      "Epoch [11/30], Time: 12.66s, Train Loss: 0.0274, Train Accuracy: 99.13%, Val Accuracy: 98.23%, LR: 0.000125\n",
      "Epoch [12/30], Time: 12.69s, Train Loss: 0.0201, Train Accuracy: 99.37%, Val Accuracy: 98.20%, LR: 0.000125\n",
      "Epoch [13/30], Time: 13.02s, Train Loss: 0.0172, Train Accuracy: 99.43%, Val Accuracy: 98.19%, LR: 0.000125\n",
      "Epoch [14/30], Time: 13.10s, Train Loss: 0.0153, Train Accuracy: 99.50%, Val Accuracy: 98.23%, LR: 0.000125\n",
      "Epoch [15/30], Time: 12.53s, Train Loss: 0.0137, Train Accuracy: 99.57%, Val Accuracy: 98.29%, LR: 0.000125\n",
      "Epoch [16/30], Time: 12.70s, Train Loss: 0.0136, Train Accuracy: 99.58%, Val Accuracy: 98.39%, LR: 0.000125\n",
      "Epoch [17/30], Time: 12.75s, Train Loss: 0.0119, Train Accuracy: 99.63%, Val Accuracy: 98.43%, LR: 0.000125\n",
      "Epoch [18/30], Time: 12.81s, Train Loss: 0.0110, Train Accuracy: 99.66%, Val Accuracy: 98.32%, LR: 0.000125\n",
      "Epoch [19/30], Time: 12.69s, Train Loss: 0.0111, Train Accuracy: 99.63%, Val Accuracy: 98.36%, LR: 0.000125\n",
      "Epoch [20/30], Time: 12.75s, Train Loss: 0.0096, Train Accuracy: 99.72%, Val Accuracy: 98.41%, LR: 0.000016\n",
      "Epoch [21/30], Time: 12.83s, Train Loss: 0.0088, Train Accuracy: 99.74%, Val Accuracy: 98.34%, LR: 0.000016\n",
      "Epoch [22/30], Time: 12.61s, Train Loss: 0.0094, Train Accuracy: 99.68%, Val Accuracy: 98.40%, LR: 0.000016\n",
      "Epoch [23/30], Time: 12.65s, Train Loss: 0.0086, Train Accuracy: 99.73%, Val Accuracy: 98.39%, LR: 0.000016\n",
      "Epoch [24/30], Time: 12.68s, Train Loss: 0.0081, Train Accuracy: 99.77%, Val Accuracy: 98.40%, LR: 0.000016\n",
      "Epoch [25/30], Time: 12.69s, Train Loss: 0.0082, Train Accuracy: 99.75%, Val Accuracy: 98.41%, LR: 0.000016\n",
      "Epoch [26/30], Time: 12.78s, Train Loss: 0.0075, Train Accuracy: 99.80%, Val Accuracy: 98.36%, LR: 0.000016\n",
      "Epoch [27/30], Time: 12.67s, Train Loss: 0.0085, Train Accuracy: 99.76%, Val Accuracy: 98.37%, LR: 0.000016\n",
      "Epoch [28/30], Time: 12.76s, Train Loss: 0.0086, Train Accuracy: 99.76%, Val Accuracy: 98.43%, LR: 0.000016\n",
      "Epoch [29/30], Time: 12.77s, Train Loss: 0.0081, Train Accuracy: 99.75%, Val Accuracy: 98.43%, LR: 0.000016\n",
      "Epoch [30/30], Time: 12.73s, Train Loss: 0.0068, Train Accuracy: 99.81%, Val Accuracy: 98.38%, LR: 0.000002\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 1 , Saving pretrained model and classifier to trained_models/part_1/mnist.pth ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "---------------------------- model saved -----------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 1 ,Training cifar model ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR-10 dataset downloaded successfully!\n",
      "Train size: 40000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Initializing weights ....\n",
      "Initializing weights DONE\n",
      "Epoch [1/40], Time: 12.27s, Train Loss: 0.1774, Val Loss: 0.1397, LR: 0.0010000\n",
      "Epoch [2/40], Time: 12.00s, Train Loss: 0.1324, Val Loss: 0.1237, LR: 0.0010000\n",
      "Epoch [3/40], Time: 12.32s, Train Loss: 0.1198, Val Loss: 0.1129, LR: 0.0010000\n",
      "Epoch [4/40], Time: 12.40s, Train Loss: 0.1130, Val Loss: 0.1089, LR: 0.0010000\n",
      "Epoch [5/40], Time: 12.34s, Train Loss: 0.1088, Val Loss: 0.1042, LR: 0.0010000\n",
      "Epoch [6/40], Time: 12.07s, Train Loss: 0.1050, Val Loss: 0.0997, LR: 0.0010000\n",
      "Epoch [7/40], Time: 12.60s, Train Loss: 0.1030, Val Loss: 0.0995, LR: 0.0010000\n",
      "Epoch [8/40], Time: 12.20s, Train Loss: 0.1017, Val Loss: 0.0977, LR: 0.0010000\n",
      "Epoch [9/40], Time: 12.27s, Train Loss: 0.1006, Val Loss: 0.0971, LR: 0.0010000\n",
      "Epoch [10/40], Time: 12.37s, Train Loss: 0.0996, Val Loss: 0.0964, LR: 0.0010000\n",
      "Epoch [11/40], Time: 12.33s, Train Loss: 0.0989, Val Loss: 0.0958, LR: 0.0010000\n",
      "Epoch [12/40], Time: 12.41s, Train Loss: 0.0984, Val Loss: 0.0966, LR: 0.0010000\n",
      "Epoch [13/40], Time: 12.44s, Train Loss: 0.0982, Val Loss: 0.0962, LR: 0.0010000\n",
      "Epoch [14/40], Time: 12.17s, Train Loss: 0.0973, Val Loss: 0.0962, LR: 0.0010000\n",
      "Epoch [15/40], Time: 12.28s, Train Loss: 0.0968, Val Loss: 0.0957, LR: 0.0010000\n",
      "Epoch [16/40], Time: 12.24s, Train Loss: 0.0970, Val Loss: 0.0952, LR: 0.0010000\n",
      "Epoch [17/40], Time: 12.34s, Train Loss: 0.0965, Val Loss: 0.0941, LR: 0.0010000\n",
      "Epoch [18/40], Time: 12.42s, Train Loss: 0.0960, Val Loss: 0.0940, LR: 0.0010000\n",
      "Epoch [19/40], Time: 12.22s, Train Loss: 0.0959, Val Loss: 0.0940, LR: 0.0010000\n",
      "Epoch [20/40], Time: 12.49s, Train Loss: 0.0957, Val Loss: 0.0948, LR: 0.0010000\n",
      "Epoch [21/40], Time: 12.14s, Train Loss: 0.0952, Val Loss: 0.0945, LR: 0.0010000\n",
      "Epoch [22/40], Time: 12.36s, Train Loss: 0.0951, Val Loss: 0.0949, LR: 0.0010000\n",
      "Epoch [23/40], Time: 12.30s, Train Loss: 0.0948, Val Loss: 0.0932, LR: 0.0010000\n",
      "Epoch [24/40], Time: 12.46s, Train Loss: 0.0945, Val Loss: 0.0937, LR: 0.0010000\n",
      "Epoch [25/40], Time: 12.25s, Train Loss: 0.0944, Val Loss: 0.0928, LR: 0.0010000\n",
      "Epoch [26/40], Time: 12.43s, Train Loss: 0.0940, Val Loss: 0.0935, LR: 0.0010000\n",
      "Epoch [27/40], Time: 12.34s, Train Loss: 0.0940, Val Loss: 0.0935, LR: 0.0010000\n",
      "Epoch [28/40], Time: 12.34s, Train Loss: 0.0939, Val Loss: 0.0933, LR: 0.0010000\n",
      "Epoch [29/40], Time: 12.24s, Train Loss: 0.0939, Val Loss: 0.0937, LR: 0.0010000\n",
      "Epoch [30/40], Time: 12.47s, Train Loss: 0.0936, Val Loss: 0.0929, LR: 0.0010000\n",
      "Epoch [31/40], Time: 12.50s, Train Loss: 0.0933, Val Loss: 0.0929, LR: 0.0001250\n",
      "Epoch [32/40], Time: 12.51s, Train Loss: 0.0912, Val Loss: 0.0912, LR: 0.0001250\n",
      "Epoch [33/40], Time: 12.37s, Train Loss: 0.0911, Val Loss: 0.0912, LR: 0.0001250\n",
      "Epoch [34/40], Time: 12.25s, Train Loss: 0.0911, Val Loss: 0.0911, LR: 0.0001250\n",
      "Epoch [35/40], Time: 12.24s, Train Loss: 0.0910, Val Loss: 0.0911, LR: 0.0001250\n",
      "Epoch [36/40], Time: 12.34s, Train Loss: 0.0909, Val Loss: 0.0912, LR: 0.0001250\n",
      "Epoch [37/40], Time: 12.32s, Train Loss: 0.0909, Val Loss: 0.0913, LR: 0.0001250\n",
      "Epoch [38/40], Time: 12.32s, Train Loss: 0.0911, Val Loss: 0.0913, LR: 0.0001250\n",
      "Epoch [39/40], Time: 12.28s, Train Loss: 0.0908, Val Loss: 0.0912, LR: 0.0001250\n",
      "Epoch [40/40], Time: 12.40s, Train Loss: 0.0908, Val Loss: 0.0912, LR: 0.0001250\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 1 , Training classifier for the cifar encoder\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Epoch [1/30], Time: 14.92s, Train Loss: 1.6493, Train Accuracy: 41.19%, Val Accuracy: 49.82%, LR: 0.001000\n",
      "Epoch [2/30], Time: 14.75s, Train Loss: 1.4370, Train Accuracy: 48.82%, Val Accuracy: 52.32%, LR: 0.001000\n",
      "Epoch [3/30], Time: 14.62s, Train Loss: 1.3502, Train Accuracy: 51.87%, Val Accuracy: 54.13%, LR: 0.001000\n",
      "Epoch [4/30], Time: 14.44s, Train Loss: 1.2764, Train Accuracy: 54.39%, Val Accuracy: 54.72%, LR: 0.001000\n",
      "Epoch [5/30], Time: 14.61s, Train Loss: 1.2288, Train Accuracy: 56.16%, Val Accuracy: 56.11%, LR: 0.001000\n",
      "Epoch [6/30], Time: 14.71s, Train Loss: 1.1868, Train Accuracy: 57.70%, Val Accuracy: 56.71%, LR: 0.001000\n",
      "Epoch [7/30], Time: 14.72s, Train Loss: 1.1547, Train Accuracy: 58.54%, Val Accuracy: 56.71%, LR: 0.001000\n",
      "Epoch [8/30], Time: 14.70s, Train Loss: 1.1161, Train Accuracy: 60.28%, Val Accuracy: 56.39%, LR: 0.001000\n",
      "Epoch [9/30], Time: 14.72s, Train Loss: 1.0886, Train Accuracy: 60.74%, Val Accuracy: 57.34%, LR: 0.001000\n",
      "Epoch [10/30], Time: 14.64s, Train Loss: 1.0702, Train Accuracy: 61.69%, Val Accuracy: 57.83%, LR: 0.000125\n",
      "Epoch [11/30], Time: 14.58s, Train Loss: 0.9660, Train Accuracy: 65.48%, Val Accuracy: 59.00%, LR: 0.000125\n",
      "Epoch [12/30], Time: 14.75s, Train Loss: 0.9311, Train Accuracy: 66.74%, Val Accuracy: 59.78%, LR: 0.000125\n",
      "Epoch [13/30], Time: 14.64s, Train Loss: 0.9056, Train Accuracy: 67.85%, Val Accuracy: 59.13%, LR: 0.000125\n",
      "Epoch [14/30], Time: 14.55s, Train Loss: 0.8995, Train Accuracy: 67.82%, Val Accuracy: 58.97%, LR: 0.000125\n",
      "Epoch [15/30], Time: 14.45s, Train Loss: 0.8887, Train Accuracy: 68.42%, Val Accuracy: 59.11%, LR: 0.000125\n",
      "Epoch [16/30], Time: 14.40s, Train Loss: 0.8707, Train Accuracy: 68.81%, Val Accuracy: 59.53%, LR: 0.000125\n",
      "Epoch [17/30], Time: 14.41s, Train Loss: 0.8662, Train Accuracy: 69.06%, Val Accuracy: 59.22%, LR: 0.000125\n",
      "Epoch [18/30], Time: 14.45s, Train Loss: 0.8596, Train Accuracy: 69.11%, Val Accuracy: 59.26%, LR: 0.000125\n",
      "Epoch [19/30], Time: 14.38s, Train Loss: 0.8546, Train Accuracy: 69.33%, Val Accuracy: 59.58%, LR: 0.000125\n",
      "Epoch [20/30], Time: 14.95s, Train Loss: 0.8381, Train Accuracy: 70.03%, Val Accuracy: 59.65%, LR: 0.000016\n",
      "Epoch [21/30], Time: 14.64s, Train Loss: 0.8251, Train Accuracy: 70.64%, Val Accuracy: 59.66%, LR: 0.000016\n",
      "Epoch [22/30], Time: 14.56s, Train Loss: 0.8160, Train Accuracy: 70.54%, Val Accuracy: 59.54%, LR: 0.000016\n",
      "Epoch [23/30], Time: 14.61s, Train Loss: 0.8200, Train Accuracy: 70.83%, Val Accuracy: 59.67%, LR: 0.000016\n",
      "Epoch [24/30], Time: 14.51s, Train Loss: 0.8152, Train Accuracy: 70.85%, Val Accuracy: 59.51%, LR: 0.000016\n",
      "Epoch [25/30], Time: 14.49s, Train Loss: 0.8155, Train Accuracy: 70.79%, Val Accuracy: 59.73%, LR: 0.000016\n",
      "Epoch [26/30], Time: 14.77s, Train Loss: 0.8189, Train Accuracy: 70.64%, Val Accuracy: 59.48%, LR: 0.000016\n",
      "Epoch [27/30], Time: 14.69s, Train Loss: 0.8131, Train Accuracy: 71.20%, Val Accuracy: 59.57%, LR: 0.000016\n",
      "Epoch [28/30], Time: 14.48s, Train Loss: 0.8096, Train Accuracy: 71.18%, Val Accuracy: 59.81%, LR: 0.000016\n",
      "Epoch [29/30], Time: 14.66s, Train Loss: 0.8079, Train Accuracy: 71.22%, Val Accuracy: 59.74%, LR: 0.000016\n",
      "Epoch [30/30], Time: 14.54s, Train Loss: 0.8112, Train Accuracy: 71.03%, Val Accuracy: 59.63%, LR: 0.000002\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 1 , Saving pretrained model and classifier to trained_models/part_1/cifar.pth ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "---------------------------- model saved -----------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 2 ,Training mnist model  WITH CLASSIFIER ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "MNIST dataset downloaded successfully!\n",
      "Train size: 50000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Epoch [1/40], Time: 11.30s, Train Loss: 0.1547, Train Accuracy: 95.46%, Val Accuracy: 97.78%, LR: 0.0010000\n",
      "Epoch [2/40], Time: 11.21s, Train Loss: 0.0699, Train Accuracy: 97.95%, Val Accuracy: 98.28%, LR: 0.0010000\n",
      "Epoch [3/40], Time: 11.24s, Train Loss: 0.0534, Train Accuracy: 98.33%, Val Accuracy: 98.28%, LR: 0.0010000\n",
      "Epoch [4/40], Time: 11.29s, Train Loss: 0.0412, Train Accuracy: 98.73%, Val Accuracy: 98.45%, LR: 0.0010000\n",
      "Epoch [5/40], Time: 11.09s, Train Loss: 0.0359, Train Accuracy: 98.88%, Val Accuracy: 98.23%, LR: 0.0010000\n",
      "Epoch [6/40], Time: 11.16s, Train Loss: 0.0299, Train Accuracy: 99.04%, Val Accuracy: 98.60%, LR: 0.0010000\n",
      "Epoch [7/40], Time: 11.18s, Train Loss: 0.0247, Train Accuracy: 99.23%, Val Accuracy: 98.55%, LR: 0.0010000\n",
      "Epoch [8/40], Time: 11.13s, Train Loss: 0.0242, Train Accuracy: 99.24%, Val Accuracy: 98.54%, LR: 0.0010000\n",
      "Epoch [9/40], Time: 11.34s, Train Loss: 0.0208, Train Accuracy: 99.34%, Val Accuracy: 98.58%, LR: 0.0010000\n",
      "Epoch [10/40], Time: 11.14s, Train Loss: 0.0195, Train Accuracy: 99.38%, Val Accuracy: 98.23%, LR: 0.0010000\n",
      "Epoch [11/40], Time: 11.25s, Train Loss: 0.0156, Train Accuracy: 99.50%, Val Accuracy: 98.57%, LR: 0.0010000\n",
      "Epoch [12/40], Time: 11.21s, Train Loss: 0.0169, Train Accuracy: 99.47%, Val Accuracy: 98.66%, LR: 0.0001250\n",
      "Epoch [13/40], Time: 11.26s, Train Loss: 0.0071, Train Accuracy: 99.77%, Val Accuracy: 98.87%, LR: 0.0001250\n",
      "Epoch [14/40], Time: 11.49s, Train Loss: 0.0042, Train Accuracy: 99.87%, Val Accuracy: 98.91%, LR: 0.0001250\n",
      "Epoch [15/40], Time: 11.51s, Train Loss: 0.0028, Train Accuracy: 99.93%, Val Accuracy: 98.93%, LR: 0.0001250\n",
      "Epoch [16/40], Time: 11.85s, Train Loss: 0.0023, Train Accuracy: 99.95%, Val Accuracy: 98.90%, LR: 0.0001250\n",
      "Epoch [17/40], Time: 11.39s, Train Loss: 0.0022, Train Accuracy: 99.95%, Val Accuracy: 98.92%, LR: 0.0001250\n",
      "Epoch [18/40], Time: 11.60s, Train Loss: 0.0015, Train Accuracy: 99.98%, Val Accuracy: 98.93%, LR: 0.0001250\n",
      "Epoch [19/40], Time: 11.65s, Train Loss: 0.0013, Train Accuracy: 99.97%, Val Accuracy: 98.93%, LR: 0.0000156\n",
      "Epoch [20/40], Time: 11.67s, Train Loss: 0.0009, Train Accuracy: 99.98%, Val Accuracy: 98.94%, LR: 0.0000156\n",
      "Epoch [21/40], Time: 11.56s, Train Loss: 0.0010, Train Accuracy: 99.98%, Val Accuracy: 98.96%, LR: 0.0000156\n",
      "Epoch [22/40], Time: 11.82s, Train Loss: 0.0008, Train Accuracy: 99.99%, Val Accuracy: 98.93%, LR: 0.0000156\n",
      "Epoch [23/40], Time: 11.66s, Train Loss: 0.0010, Train Accuracy: 99.98%, Val Accuracy: 98.96%, LR: 0.0000156\n",
      "Epoch [24/40], Time: 11.90s, Train Loss: 0.0009, Train Accuracy: 99.98%, Val Accuracy: 98.94%, LR: 0.0000156\n",
      "Epoch [25/40], Time: 11.66s, Train Loss: 0.0007, Train Accuracy: 99.99%, Val Accuracy: 98.93%, LR: 0.0000020\n",
      "Epoch [26/40], Time: 11.85s, Train Loss: 0.0007, Train Accuracy: 99.99%, Val Accuracy: 98.92%, LR: 0.0000020\n",
      "Epoch [27/40], Time: 11.59s, Train Loss: 0.0007, Train Accuracy: 99.98%, Val Accuracy: 98.92%, LR: 0.0000020\n",
      "Epoch [28/40], Time: 11.69s, Train Loss: 0.0008, Train Accuracy: 99.99%, Val Accuracy: 98.95%, LR: 0.0000020\n",
      "Epoch [29/40], Time: 11.68s, Train Loss: 0.0008, Train Accuracy: 99.99%, Val Accuracy: 98.90%, LR: 0.0000020\n",
      "Epoch [30/40], Time: 11.89s, Train Loss: 0.0007, Train Accuracy: 99.99%, Val Accuracy: 98.96%, LR: 0.0000020\n",
      "Epoch [31/40], Time: 12.22s, Train Loss: 0.0007, Train Accuracy: 99.99%, Val Accuracy: 98.92%, LR: 0.0000002\n",
      "Epoch [32/40], Time: 11.72s, Train Loss: 0.0008, Train Accuracy: 99.99%, Val Accuracy: 98.93%, LR: 0.0000002\n",
      "Epoch [33/40], Time: 11.60s, Train Loss: 0.0007, Train Accuracy: 99.98%, Val Accuracy: 98.96%, LR: 0.0000002\n",
      "Epoch [34/40], Time: 11.77s, Train Loss: 0.0005, Train Accuracy: 99.99%, Val Accuracy: 98.93%, LR: 0.0000002\n",
      "Epoch [35/40], Time: 11.75s, Train Loss: 0.0008, Train Accuracy: 99.99%, Val Accuracy: 98.95%, LR: 0.0000002\n",
      "Epoch [36/40], Time: 11.94s, Train Loss: 0.0011, Train Accuracy: 99.98%, Val Accuracy: 98.89%, LR: 0.0000002\n",
      "Epoch [37/40], Time: 11.55s, Train Loss: 0.0006, Train Accuracy: 99.99%, Val Accuracy: 98.93%, LR: 0.0000001\n",
      "Epoch [38/40], Time: 11.73s, Train Loss: 0.0006, Train Accuracy: 99.99%, Val Accuracy: 98.94%, LR: 0.0000001\n",
      "Epoch [39/40], Time: 11.53s, Train Loss: 0.0006, Train Accuracy: 99.99%, Val Accuracy: 98.97%, LR: 0.0000001\n",
      "Epoch [40/40], Time: 11.97s, Train Loss: 0.0008, Train Accuracy: 99.98%, Val Accuracy: 98.90%, LR: 0.0000001\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 2 , Saving pretrained model and classifier to trained_models/part_2/mnist.pth ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "---------------------------- model saved -----------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 2 ,Training cifar model  WITH CLASSIFIER ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR-10 dataset downloaded successfully!\n",
      "Train size: 40000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Initializing weights ....\n",
      "Initializing weights DONE\n",
      "Epoch [1/40], Time: 12.40s, Train Loss: 1.4505, Train Accuracy: 47.58%, Val Accuracy: 56.82%, LR: 0.0010000\n",
      "Epoch [2/40], Time: 12.14s, Train Loss: 1.0625, Train Accuracy: 62.53%, Val Accuracy: 64.90%, LR: 0.0010000\n",
      "Epoch [3/40], Time: 12.24s, Train Loss: 0.8770, Train Accuracy: 69.36%, Val Accuracy: 67.31%, LR: 0.0010000\n",
      "Epoch [4/40], Time: 12.18s, Train Loss: 0.7356, Train Accuracy: 74.44%, Val Accuracy: 68.31%, LR: 0.0010000\n",
      "Epoch [5/40], Time: 12.08s, Train Loss: 0.6129, Train Accuracy: 78.97%, Val Accuracy: 69.17%, LR: 0.0010000\n",
      "Epoch [6/40], Time: 12.28s, Train Loss: 0.5075, Train Accuracy: 82.74%, Val Accuracy: 69.24%, LR: 0.0010000\n",
      "Epoch [7/40], Time: 12.06s, Train Loss: 0.4185, Train Accuracy: 85.67%, Val Accuracy: 68.96%, LR: 0.0010000\n",
      "Epoch [8/40], Time: 12.23s, Train Loss: 0.3464, Train Accuracy: 88.30%, Val Accuracy: 69.07%, LR: 0.0010000\n",
      "Epoch [9/40], Time: 12.02s, Train Loss: 0.2856, Train Accuracy: 90.23%, Val Accuracy: 67.93%, LR: 0.0010000\n",
      "Epoch [10/40], Time: 12.13s, Train Loss: 0.2438, Train Accuracy: 91.68%, Val Accuracy: 67.23%, LR: 0.0010000\n",
      "Epoch [11/40], Time: 12.25s, Train Loss: 0.2049, Train Accuracy: 93.14%, Val Accuracy: 67.79%, LR: 0.0010000\n",
      "Epoch [12/40], Time: 12.31s, Train Loss: 0.1770, Train Accuracy: 93.96%, Val Accuracy: 67.92%, LR: 0.0001250\n",
      "Epoch [13/40], Time: 12.18s, Train Loss: 0.0884, Train Accuracy: 97.20%, Val Accuracy: 69.19%, LR: 0.0001250\n",
      "Epoch [14/40], Time: 12.28s, Train Loss: 0.0503, Train Accuracy: 98.61%, Val Accuracy: 69.40%, LR: 0.0001250\n",
      "Epoch [15/40], Time: 12.36s, Train Loss: 0.0345, Train Accuracy: 99.07%, Val Accuracy: 69.08%, LR: 0.0001250\n",
      "Epoch [16/40], Time: 12.61s, Train Loss: 0.0258, Train Accuracy: 99.38%, Val Accuracy: 69.06%, LR: 0.0001250\n",
      "Epoch [17/40], Time: 12.23s, Train Loss: 0.0208, Train Accuracy: 99.50%, Val Accuracy: 68.74%, LR: 0.0001250\n",
      "Epoch [18/40], Time: 12.25s, Train Loss: 0.0160, Train Accuracy: 99.61%, Val Accuracy: 68.86%, LR: 0.0001250\n",
      "Epoch [19/40], Time: 12.30s, Train Loss: 0.0136, Train Accuracy: 99.67%, Val Accuracy: 68.77%, LR: 0.0001250\n",
      "Epoch [20/40], Time: 12.55s, Train Loss: 0.0131, Train Accuracy: 99.67%, Val Accuracy: 68.88%, LR: 0.0000156\n",
      "Epoch [21/40], Time: 12.10s, Train Loss: 0.0092, Train Accuracy: 99.80%, Val Accuracy: 68.83%, LR: 0.0000156\n",
      "Epoch [22/40], Time: 11.97s, Train Loss: 0.0084, Train Accuracy: 99.83%, Val Accuracy: 68.96%, LR: 0.0000156\n",
      "Epoch [23/40], Time: 12.40s, Train Loss: 0.0075, Train Accuracy: 99.85%, Val Accuracy: 68.83%, LR: 0.0000156\n",
      "Epoch [24/40], Time: 12.13s, Train Loss: 0.0075, Train Accuracy: 99.84%, Val Accuracy: 69.27%, LR: 0.0000156\n",
      "Epoch [25/40], Time: 12.11s, Train Loss: 0.0073, Train Accuracy: 99.83%, Val Accuracy: 68.95%, LR: 0.0000156\n",
      "Epoch [26/40], Time: 12.12s, Train Loss: 0.0070, Train Accuracy: 99.85%, Val Accuracy: 69.29%, LR: 0.0000020\n",
      "Epoch [27/40], Time: 11.97s, Train Loss: 0.0066, Train Accuracy: 99.87%, Val Accuracy: 68.91%, LR: 0.0000020\n",
      "Epoch [28/40], Time: 12.05s, Train Loss: 0.0062, Train Accuracy: 99.89%, Val Accuracy: 69.05%, LR: 0.0000020\n",
      "Epoch [29/40], Time: 12.31s, Train Loss: 0.0062, Train Accuracy: 99.88%, Val Accuracy: 68.92%, LR: 0.0000020\n",
      "Epoch [30/40], Time: 12.07s, Train Loss: 0.0060, Train Accuracy: 99.87%, Val Accuracy: 69.00%, LR: 0.0000020\n",
      "Epoch [31/40], Time: 12.55s, Train Loss: 0.0066, Train Accuracy: 99.87%, Val Accuracy: 69.06%, LR: 0.0000020\n",
      "Epoch [32/40], Time: 12.40s, Train Loss: 0.0055, Train Accuracy: 99.90%, Val Accuracy: 69.01%, LR: 0.0000002\n",
      "Epoch [33/40], Time: 12.20s, Train Loss: 0.0059, Train Accuracy: 99.89%, Val Accuracy: 68.98%, LR: 0.0000002\n",
      "Epoch [34/40], Time: 13.15s, Train Loss: 0.0057, Train Accuracy: 99.87%, Val Accuracy: 68.81%, LR: 0.0000002\n",
      "Epoch [35/40], Time: 12.34s, Train Loss: 0.0067, Train Accuracy: 99.85%, Val Accuracy: 69.01%, LR: 0.0000002\n",
      "Epoch [36/40], Time: 12.17s, Train Loss: 0.0054, Train Accuracy: 99.90%, Val Accuracy: 68.88%, LR: 0.0000002\n",
      "Epoch [37/40], Time: 12.32s, Train Loss: 0.0056, Train Accuracy: 99.91%, Val Accuracy: 69.06%, LR: 0.0000002\n",
      "Epoch [38/40], Time: 12.11s, Train Loss: 0.0060, Train Accuracy: 99.90%, Val Accuracy: 69.06%, LR: 0.0000001\n",
      "Epoch [39/40], Time: 12.05s, Train Loss: 0.0054, Train Accuracy: 99.89%, Val Accuracy: 68.86%, LR: 0.0000001\n",
      "Epoch [40/40], Time: 12.27s, Train Loss: 0.0054, Train Accuracy: 99.89%, Val Accuracy: 68.91%, LR: 0.0000001\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 2 , Saving pretrained model and classifier to trained_models/part_2/cifar.pth ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "---------------------------- model saved -----------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 3 ,Training mnist model ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "MNIST dataset downloaded successfully!\n",
      "Train size: 50000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Epoch [1/40], Time: 5.82s, Train Loss: 4.8122, Val Loss: 2.1902, LR: 0.001000\n",
      "Epoch [2/40], Time: 6.04s, Train Loss: 3.3809, Val Loss: 1.7676, LR: 0.001000\n",
      "Epoch [3/40], Time: 6.21s, Train Loss: 2.7354, Val Loss: 1.3195, LR: 0.001000\n",
      "Epoch [4/40], Time: 5.96s, Train Loss: 2.2721, Val Loss: 0.8856, LR: 0.001000\n",
      "Epoch [5/40], Time: 6.22s, Train Loss: 1.8818, Val Loss: 0.8951, LR: 0.001000\n",
      "Epoch [6/40], Time: 6.07s, Train Loss: 1.8300, Val Loss: 0.7975, LR: 0.001000\n",
      "Epoch [7/40], Time: 5.99s, Train Loss: 1.6670, Val Loss: 0.6863, LR: 0.001000\n",
      "Epoch [8/40], Time: 5.91s, Train Loss: 1.6147, Val Loss: 0.5773, LR: 0.001000\n",
      "Epoch [9/40], Time: 6.24s, Train Loss: 1.5385, Val Loss: 0.5082, LR: 0.001000\n",
      "Epoch [10/40], Time: 6.18s, Train Loss: 1.3458, Val Loss: 0.5395, LR: 0.001000\n",
      "Epoch [11/40], Time: 6.00s, Train Loss: 1.3250, Val Loss: 0.4413, LR: 0.001000\n",
      "Epoch [12/40], Time: 5.89s, Train Loss: 1.2352, Val Loss: 0.4142, LR: 0.001000\n",
      "Epoch [13/40], Time: 7.12s, Train Loss: 1.3067, Val Loss: 0.4059, LR: 0.001000\n",
      "Epoch [14/40], Time: 8.29s, Train Loss: 1.2269, Val Loss: 0.4166, LR: 0.001000\n",
      "Epoch [15/40], Time: 7.47s, Train Loss: 1.1729, Val Loss: 0.4009, LR: 0.001000\n",
      "Epoch [16/40], Time: 6.83s, Train Loss: 1.1454, Val Loss: 0.4084, LR: 0.001000\n",
      "Epoch [17/40], Time: 6.53s, Train Loss: 1.1275, Val Loss: 0.3651, LR: 0.001000\n",
      "Epoch [18/40], Time: 6.23s, Train Loss: 1.0562, Val Loss: 0.3666, LR: 0.001000\n",
      "Epoch [19/40], Time: 6.59s, Train Loss: 1.0835, Val Loss: 0.3683, LR: 0.001000\n",
      "Epoch [20/40], Time: 6.29s, Train Loss: 1.0619, Val Loss: 0.3795, LR: 0.001000\n",
      "Epoch [21/40], Time: 6.09s, Train Loss: 1.0303, Val Loss: 0.3753, LR: 0.001000\n",
      "Epoch [22/40], Time: 6.48s, Train Loss: 1.0248, Val Loss: 0.3182, LR: 0.001000\n",
      "Epoch [23/40], Time: 6.20s, Train Loss: 1.0212, Val Loss: 0.2937, LR: 0.001000\n",
      "Epoch [24/40], Time: 6.25s, Train Loss: 0.9339, Val Loss: 0.3192, LR: 0.001000\n",
      "Epoch [25/40], Time: 6.07s, Train Loss: 0.8828, Val Loss: 0.2905, LR: 0.001000\n",
      "Epoch [26/40], Time: 6.28s, Train Loss: 0.8640, Val Loss: 0.2868, LR: 0.001000\n",
      "Epoch [27/40], Time: 6.16s, Train Loss: 0.8780, Val Loss: 0.3315, LR: 0.001000\n",
      "Epoch [28/40], Time: 6.05s, Train Loss: 0.9019, Val Loss: 0.2963, LR: 0.001000\n",
      "Epoch [29/40], Time: 5.95s, Train Loss: 0.8514, Val Loss: 0.2976, LR: 0.001000\n",
      "Epoch [30/40], Time: 5.89s, Train Loss: 0.9184, Val Loss: 0.3131, LR: 0.001000\n",
      "Epoch [31/40], Time: 6.13s, Train Loss: 0.8041, Val Loss: 0.3039, LR: 0.001000\n",
      "Epoch [32/40], Time: 6.04s, Train Loss: 0.8631, Val Loss: 0.2636, LR: 0.001000\n",
      "Epoch [33/40], Time: 5.82s, Train Loss: 0.8689, Val Loss: 0.2468, LR: 0.001000\n",
      "Epoch [34/40], Time: 6.01s, Train Loss: 0.8592, Val Loss: 0.2958, LR: 0.001000\n",
      "Epoch [35/40], Time: 5.98s, Train Loss: 0.8109, Val Loss: 0.3438, LR: 0.001000\n",
      "Epoch [36/40], Time: 6.06s, Train Loss: 0.8840, Val Loss: 0.2521, LR: 0.001000\n",
      "Epoch [37/40], Time: 6.13s, Train Loss: 0.8282, Val Loss: 0.3832, LR: 0.001000\n",
      "Epoch [38/40], Time: 6.09s, Train Loss: 0.8791, Val Loss: 0.2684, LR: 0.001000\n",
      "Epoch [39/40], Time: 6.31s, Train Loss: 0.8565, Val Loss: 0.2227, LR: 0.001000\n",
      "Epoch [40/40], Time: 5.99s, Train Loss: 0.7373, Val Loss: 0.2472, LR: 0.001000\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 3 , Training classifier for the mnist encoder\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Epoch [1/30], Time: 8.92s, Train Loss: 0.2680, Train Accuracy: 91.97%, Val Accuracy: 95.68%, LR: 0.001000\n",
      "Epoch [2/30], Time: 8.88s, Train Loss: 0.1406, Train Accuracy: 95.57%, Val Accuracy: 96.85%, LR: 0.001000\n",
      "Epoch [3/30], Time: 8.86s, Train Loss: 0.1127, Train Accuracy: 96.33%, Val Accuracy: 97.04%, LR: 0.001000\n",
      "Epoch [4/30], Time: 9.00s, Train Loss: 0.1036, Train Accuracy: 96.65%, Val Accuracy: 96.81%, LR: 0.001000\n",
      "Epoch [5/30], Time: 8.98s, Train Loss: 0.0943, Train Accuracy: 96.93%, Val Accuracy: 97.48%, LR: 0.001000\n",
      "Epoch [6/30], Time: 8.95s, Train Loss: 0.0880, Train Accuracy: 97.18%, Val Accuracy: 97.23%, LR: 0.001000\n",
      "Epoch [7/30], Time: 8.84s, Train Loss: 0.0817, Train Accuracy: 97.37%, Val Accuracy: 97.88%, LR: 0.001000\n",
      "Epoch [8/30], Time: 8.85s, Train Loss: 0.0780, Train Accuracy: 97.47%, Val Accuracy: 97.97%, LR: 0.001000\n",
      "Epoch [9/30], Time: 8.95s, Train Loss: 0.0765, Train Accuracy: 97.50%, Val Accuracy: 97.70%, LR: 0.001000\n",
      "Epoch [10/30], Time: 8.94s, Train Loss: 0.0734, Train Accuracy: 97.60%, Val Accuracy: 97.91%, LR: 0.000125\n",
      "Epoch [11/30], Time: 8.96s, Train Loss: 0.0533, Train Accuracy: 98.24%, Val Accuracy: 98.26%, LR: 0.000125\n",
      "Epoch [12/30], Time: 8.90s, Train Loss: 0.0468, Train Accuracy: 98.52%, Val Accuracy: 98.29%, LR: 0.000125\n",
      "Epoch [13/30], Time: 8.92s, Train Loss: 0.0431, Train Accuracy: 98.60%, Val Accuracy: 98.39%, LR: 0.000125\n",
      "Epoch [14/30], Time: 8.91s, Train Loss: 0.0398, Train Accuracy: 98.73%, Val Accuracy: 98.36%, LR: 0.000125\n",
      "Epoch [15/30], Time: 8.97s, Train Loss: 0.0394, Train Accuracy: 98.73%, Val Accuracy: 98.39%, LR: 0.000125\n",
      "Epoch [16/30], Time: 8.86s, Train Loss: 0.0370, Train Accuracy: 98.80%, Val Accuracy: 98.41%, LR: 0.000125\n",
      "Epoch [17/30], Time: 8.89s, Train Loss: 0.0360, Train Accuracy: 98.84%, Val Accuracy: 98.39%, LR: 0.000125\n",
      "Epoch [18/30], Time: 8.90s, Train Loss: 0.0346, Train Accuracy: 98.88%, Val Accuracy: 98.44%, LR: 0.000125\n",
      "Epoch [19/30], Time: 9.01s, Train Loss: 0.0328, Train Accuracy: 98.94%, Val Accuracy: 98.46%, LR: 0.000125\n",
      "Epoch [20/30], Time: 8.96s, Train Loss: 0.0310, Train Accuracy: 99.04%, Val Accuracy: 98.48%, LR: 0.000016\n",
      "Epoch [21/30], Time: 8.99s, Train Loss: 0.0292, Train Accuracy: 99.08%, Val Accuracy: 98.48%, LR: 0.000016\n",
      "Epoch [22/30], Time: 8.91s, Train Loss: 0.0295, Train Accuracy: 99.05%, Val Accuracy: 98.54%, LR: 0.000016\n",
      "Epoch [23/30], Time: 8.91s, Train Loss: 0.0283, Train Accuracy: 99.05%, Val Accuracy: 98.53%, LR: 0.000016\n",
      "Epoch [24/30], Time: 9.00s, Train Loss: 0.0280, Train Accuracy: 99.13%, Val Accuracy: 98.58%, LR: 0.000016\n",
      "Epoch [25/30], Time: 8.96s, Train Loss: 0.0264, Train Accuracy: 99.17%, Val Accuracy: 98.50%, LR: 0.000016\n",
      "Epoch [26/30], Time: 8.96s, Train Loss: 0.0273, Train Accuracy: 99.15%, Val Accuracy: 98.50%, LR: 0.000016\n",
      "Epoch [27/30], Time: 8.83s, Train Loss: 0.0276, Train Accuracy: 99.17%, Val Accuracy: 98.53%, LR: 0.000016\n",
      "Epoch [28/30], Time: 8.88s, Train Loss: 0.0277, Train Accuracy: 99.10%, Val Accuracy: 98.54%, LR: 0.000016\n",
      "Epoch [29/30], Time: 8.87s, Train Loss: 0.0287, Train Accuracy: 99.12%, Val Accuracy: 98.53%, LR: 0.000016\n",
      "Epoch [30/30], Time: 8.80s, Train Loss: 0.0260, Train Accuracy: 99.16%, Val Accuracy: 98.48%, LR: 0.000002\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 3 , Saving pretrained model and classifier to trained_models/part_3/mnist.pth ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "---------------------------- model saved -----------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 3 ,Training cifar model ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CIFAR-10 dataset downloaded successfully!\n",
      "Train size: 40000, Validation size: 10000, Test size: 10000\n",
      "DataLoaders created successfully!\n",
      "Initializing weights ....\n",
      "Initializing weights DONE\n",
      "Epoch [1/60], Time: 9.24s, Train Loss: 2.3653, Val Loss: 0.3875, LR: 0.001000\n",
      "Epoch [2/60], Time: 8.85s, Train Loss: 1.5438, Val Loss: 0.2819, LR: 0.001000\n",
      "Epoch [3/60], Time: 9.63s, Train Loss: 1.4323, Val Loss: 0.3533, LR: 0.001000\n",
      "Epoch [4/60], Time: 9.71s, Train Loss: 1.1921, Val Loss: 0.2129, LR: 0.001000\n",
      "Epoch [5/60], Time: 9.03s, Train Loss: 1.0114, Val Loss: 0.2137, LR: 0.001000\n",
      "Epoch [6/60], Time: 8.84s, Train Loss: 1.0752, Val Loss: 0.1558, LR: 0.001000\n",
      "Epoch [7/60], Time: 8.58s, Train Loss: 0.8565, Val Loss: 0.1633, LR: 0.001000\n",
      "Epoch [8/60], Time: 8.53s, Train Loss: 0.8035, Val Loss: 0.1422, LR: 0.001000\n",
      "Epoch [9/60], Time: 9.11s, Train Loss: 0.7079, Val Loss: 0.1578, LR: 0.001000\n",
      "Epoch [10/60], Time: 9.01s, Train Loss: 0.8027, Val Loss: 0.2218, LR: 0.001000\n",
      "Epoch [11/60], Time: 8.71s, Train Loss: 0.7568, Val Loss: 0.1232, LR: 0.001000\n",
      "Epoch [12/60], Time: 8.96s, Train Loss: 0.6936, Val Loss: 0.1211, LR: 0.001000\n",
      "Epoch [13/60], Time: 8.87s, Train Loss: 0.6632, Val Loss: 0.1654, LR: 0.001000\n",
      "Epoch [14/60], Time: 8.63s, Train Loss: 0.7429, Val Loss: 0.1264, LR: 0.001000\n",
      "Epoch [15/60], Time: 8.72s, Train Loss: 0.6380, Val Loss: 0.1560, LR: 0.001000\n",
      "Epoch [16/60], Time: 8.88s, Train Loss: 0.6002, Val Loss: 0.1135, LR: 0.001000\n",
      "Epoch [17/60], Time: 9.10s, Train Loss: 0.5568, Val Loss: 0.1273, LR: 0.001000\n",
      "Epoch [18/60], Time: 8.85s, Train Loss: 0.5897, Val Loss: 0.1113, LR: 0.001000\n",
      "Epoch [19/60], Time: 8.73s, Train Loss: 0.6203, Val Loss: 0.1438, LR: 0.001000\n",
      "Epoch [20/60], Time: 8.71s, Train Loss: 0.5849, Val Loss: 0.1376, LR: 0.001000\n",
      "Epoch [21/60], Time: 8.82s, Train Loss: 0.5027, Val Loss: 0.1042, LR: 0.001000\n",
      "Epoch [22/60], Time: 9.08s, Train Loss: 0.5770, Val Loss: 0.1027, LR: 0.001000\n",
      "Epoch [23/60], Time: 8.81s, Train Loss: 0.5577, Val Loss: 0.1567, LR: 0.001000\n",
      "Epoch [24/60], Time: 8.86s, Train Loss: 0.5120, Val Loss: 0.0990, LR: 0.001000\n",
      "Epoch [25/60], Time: 8.78s, Train Loss: 0.4839, Val Loss: 0.0973, LR: 0.001000\n",
      "Epoch [26/60], Time: 8.91s, Train Loss: 0.5139, Val Loss: 0.1089, LR: 0.001000\n",
      "Epoch [27/60], Time: 8.83s, Train Loss: 0.4965, Val Loss: 0.1216, LR: 0.001000\n",
      "Epoch [28/60], Time: 8.85s, Train Loss: 0.4745, Val Loss: 0.0875, LR: 0.001000\n",
      "Epoch [29/60], Time: 8.76s, Train Loss: 0.4346, Val Loss: 0.0966, LR: 0.001000\n",
      "Epoch [30/60], Time: 8.73s, Train Loss: 0.4539, Val Loss: 0.0936, LR: 0.001000\n",
      "Epoch [31/60], Time: 8.76s, Train Loss: 0.4252, Val Loss: 0.0988, LR: 0.001000\n",
      "Epoch [32/60], Time: 9.19s, Train Loss: 0.4629, Val Loss: 0.0988, LR: 0.001000\n",
      "Epoch [33/60], Time: 8.53s, Train Loss: 0.4575, Val Loss: 0.0925, LR: 0.001000\n",
      "Epoch [34/60], Time: 8.98s, Train Loss: 0.4231, Val Loss: 0.1170, LR: 0.000125\n",
      "Epoch [35/60], Time: 8.93s, Train Loss: 0.3525, Val Loss: 0.0804, LR: 0.000125\n",
      "Epoch [36/60], Time: 8.56s, Train Loss: 0.4017, Val Loss: 0.0833, LR: 0.000125\n",
      "Epoch [37/60], Time: 9.02s, Train Loss: 0.3879, Val Loss: 0.0829, LR: 0.000125\n",
      "Epoch [38/60], Time: 8.88s, Train Loss: 0.4100, Val Loss: 0.0789, LR: 0.000125\n",
      "Epoch [39/60], Time: 9.04s, Train Loss: 0.3956, Val Loss: 0.0805, LR: 0.000125\n",
      "Epoch [40/60], Time: 9.40s, Train Loss: 0.3861, Val Loss: 0.0824, LR: 0.000125\n",
      "Epoch [41/60], Time: 9.11s, Train Loss: 0.4304, Val Loss: 0.0813, LR: 0.000125\n",
      "Epoch [42/60], Time: 9.43s, Train Loss: 0.4069, Val Loss: 0.0794, LR: 0.000125\n",
      "Epoch [43/60], Time: 8.88s, Train Loss: 0.3547, Val Loss: 0.0792, LR: 0.000125\n",
      "Epoch [44/60], Time: 9.12s, Train Loss: 0.3905, Val Loss: 0.0820, LR: 0.000016\n",
      "Epoch [45/60], Time: 9.02s, Train Loss: 0.3638, Val Loss: 0.0788, LR: 0.000016\n",
      "Epoch [46/60], Time: 9.14s, Train Loss: 0.3649, Val Loss: 0.0779, LR: 0.000016\n",
      "Epoch [47/60], Time: 9.01s, Train Loss: 0.4052, Val Loss: 0.0807, LR: 0.000016\n",
      "Epoch [48/60], Time: 9.38s, Train Loss: 0.3744, Val Loss: 0.0786, LR: 0.000016\n",
      "Epoch [49/60], Time: 9.16s, Train Loss: 0.3536, Val Loss: 0.0772, LR: 0.000016\n",
      "Epoch [50/60], Time: 8.88s, Train Loss: 0.3455, Val Loss: 0.0774, LR: 0.000016\n",
      "Epoch [51/60], Time: 9.06s, Train Loss: 0.3612, Val Loss: 0.0769, LR: 0.000016\n",
      "Epoch [52/60], Time: 9.57s, Train Loss: 0.3505, Val Loss: 0.0783, LR: 0.000016\n",
      "Epoch [53/60], Time: 9.30s, Train Loss: 0.3812, Val Loss: 0.0772, LR: 0.000016\n",
      "Epoch [54/60], Time: 9.20s, Train Loss: 0.3773, Val Loss: 0.0776, LR: 0.000016\n",
      "Epoch [55/60], Time: 8.96s, Train Loss: 0.3773, Val Loss: 0.0774, LR: 0.000016\n",
      "Epoch [56/60], Time: 9.02s, Train Loss: 0.3721, Val Loss: 0.0780, LR: 0.000016\n",
      "Epoch [57/60], Time: 8.99s, Train Loss: 0.3676, Val Loss: 0.0778, LR: 0.000002\n",
      "Epoch [58/60], Time: 8.71s, Train Loss: 0.3242, Val Loss: 0.0773, LR: 0.000002\n",
      "Epoch [59/60], Time: 9.02s, Train Loss: 0.4094, Val Loss: 0.0781, LR: 0.000002\n",
      "Epoch [60/60], Time: 9.07s, Train Loss: 0.3406, Val Loss: 0.0770, LR: 0.000002\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 3 , Training classifier for the cifar encoder\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Epoch [1/40], Time: 10.91s, Train Loss: 1.3175, Train Accuracy: 53.14%, Val Accuracy: 60.59%, LR: 0.001000\n",
      "Epoch [2/40], Time: 11.11s, Train Loss: 1.1513, Train Accuracy: 59.22%, Val Accuracy: 62.17%, LR: 0.001000\n",
      "Epoch [3/40], Time: 10.79s, Train Loss: 1.0974, Train Accuracy: 61.07%, Val Accuracy: 63.38%, LR: 0.001000\n",
      "Epoch [4/40], Time: 10.83s, Train Loss: 1.0591, Train Accuracy: 62.38%, Val Accuracy: 63.91%, LR: 0.001000\n",
      "Epoch [5/40], Time: 10.83s, Train Loss: 1.0332, Train Accuracy: 63.61%, Val Accuracy: 64.81%, LR: 0.001000\n",
      "Epoch [6/40], Time: 10.74s, Train Loss: 1.0078, Train Accuracy: 64.34%, Val Accuracy: 65.31%, LR: 0.001000\n",
      "Epoch [7/40], Time: 10.79s, Train Loss: 0.9934, Train Accuracy: 64.86%, Val Accuracy: 65.15%, LR: 0.001000\n",
      "Epoch [8/40], Time: 11.19s, Train Loss: 0.9770, Train Accuracy: 65.53%, Val Accuracy: 66.13%, LR: 0.001000\n",
      "Epoch [9/40], Time: 11.23s, Train Loss: 0.9572, Train Accuracy: 66.05%, Val Accuracy: 65.97%, LR: 0.001000\n",
      "Epoch [10/40], Time: 11.39s, Train Loss: 0.9448, Train Accuracy: 66.73%, Val Accuracy: 66.27%, LR: 0.000125\n",
      "Epoch [11/40], Time: 11.21s, Train Loss: 0.8830, Train Accuracy: 68.75%, Val Accuracy: 66.95%, LR: 0.000125\n",
      "Epoch [12/40], Time: 11.15s, Train Loss: 0.8571, Train Accuracy: 69.78%, Val Accuracy: 67.05%, LR: 0.000125\n",
      "Epoch [13/40], Time: 11.17s, Train Loss: 0.8475, Train Accuracy: 69.94%, Val Accuracy: 67.20%, LR: 0.000125\n",
      "Epoch [14/40], Time: 11.42s, Train Loss: 0.8329, Train Accuracy: 70.76%, Val Accuracy: 67.40%, LR: 0.000125\n",
      "Epoch [15/40], Time: 11.33s, Train Loss: 0.8318, Train Accuracy: 70.46%, Val Accuracy: 67.62%, LR: 0.000125\n",
      "Epoch [16/40], Time: 11.28s, Train Loss: 0.8233, Train Accuracy: 71.02%, Val Accuracy: 67.49%, LR: 0.000125\n",
      "Epoch [17/40], Time: 11.18s, Train Loss: 0.8198, Train Accuracy: 70.72%, Val Accuracy: 67.56%, LR: 0.000125\n",
      "Epoch [18/40], Time: 11.29s, Train Loss: 0.8083, Train Accuracy: 71.37%, Val Accuracy: 67.72%, LR: 0.000125\n",
      "Epoch [19/40], Time: 11.26s, Train Loss: 0.8083, Train Accuracy: 71.45%, Val Accuracy: 67.88%, LR: 0.000125\n",
      "Epoch [20/40], Time: 11.28s, Train Loss: 0.8029, Train Accuracy: 71.60%, Val Accuracy: 67.69%, LR: 0.000016\n",
      "Epoch [21/40], Time: 11.20s, Train Loss: 0.7895, Train Accuracy: 71.97%, Val Accuracy: 67.81%, LR: 0.000016\n",
      "Epoch [22/40], Time: 11.33s, Train Loss: 0.7891, Train Accuracy: 71.89%, Val Accuracy: 67.80%, LR: 0.000016\n",
      "Epoch [23/40], Time: 11.39s, Train Loss: 0.7886, Train Accuracy: 72.05%, Val Accuracy: 67.91%, LR: 0.000016\n",
      "Epoch [24/40], Time: 11.27s, Train Loss: 0.7834, Train Accuracy: 72.26%, Val Accuracy: 67.93%, LR: 0.000016\n",
      "Epoch [25/40], Time: 11.26s, Train Loss: 0.7900, Train Accuracy: 72.06%, Val Accuracy: 68.08%, LR: 0.000016\n",
      "Epoch [26/40], Time: 11.24s, Train Loss: 0.7851, Train Accuracy: 72.29%, Val Accuracy: 67.84%, LR: 0.000016\n",
      "Epoch [27/40], Time: 11.83s, Train Loss: 0.7848, Train Accuracy: 72.02%, Val Accuracy: 67.91%, LR: 0.000016\n",
      "Epoch [28/40], Time: 11.97s, Train Loss: 0.7789, Train Accuracy: 72.49%, Val Accuracy: 67.83%, LR: 0.000016\n",
      "Epoch [29/40], Time: 11.95s, Train Loss: 0.7787, Train Accuracy: 72.59%, Val Accuracy: 67.96%, LR: 0.000016\n",
      "Epoch [30/40], Time: 11.83s, Train Loss: 0.7833, Train Accuracy: 72.09%, Val Accuracy: 67.96%, LR: 0.000002\n",
      "Epoch [31/40], Time: 10.83s, Train Loss: 0.7738, Train Accuracy: 72.50%, Val Accuracy: 67.81%, LR: 0.000002\n",
      "Epoch [32/40], Time: 10.80s, Train Loss: 0.7782, Train Accuracy: 72.19%, Val Accuracy: 67.93%, LR: 0.000002\n",
      "Epoch [33/40], Time: 10.88s, Train Loss: 0.7778, Train Accuracy: 72.53%, Val Accuracy: 67.94%, LR: 0.000002\n",
      "Epoch [34/40], Time: 10.70s, Train Loss: 0.7764, Train Accuracy: 72.45%, Val Accuracy: 67.91%, LR: 0.000002\n",
      "Epoch [35/40], Time: 11.58s, Train Loss: 0.7786, Train Accuracy: 72.59%, Val Accuracy: 68.04%, LR: 0.000002\n",
      "Epoch [36/40], Time: 11.44s, Train Loss: 0.7749, Train Accuracy: 72.31%, Val Accuracy: 68.02%, LR: 0.000002\n",
      "Epoch [37/40], Time: 11.60s, Train Loss: 0.7786, Train Accuracy: 72.24%, Val Accuracy: 67.89%, LR: 0.000002\n",
      "Epoch [38/40], Time: 11.18s, Train Loss: 0.7751, Train Accuracy: 72.57%, Val Accuracy: 68.05%, LR: 0.000002\n",
      "Epoch [39/40], Time: 10.99s, Train Loss: 0.7778, Train Accuracy: 72.57%, Val Accuracy: 67.95%, LR: 0.000002\n",
      "Epoch [40/40], Time: 10.65s, Train Loss: 0.7762, Train Accuracy: 72.40%, Val Accuracy: 67.91%, LR: 0.000000\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Part 3 , Saving pretrained model and classifier to trained_models/part_3/cifar.pth ...\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "---------------------------- model saved -----------------------------\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'part_1_mnist': {'model_train_losses': [0.1320723326891051,\n",
       "   0.042626201182298956,\n",
       "   0.039883559712630405,\n",
       "   0.03813817453525408,\n",
       "   0.03705649126959426,\n",
       "   0.03620869358596594,\n",
       "   0.03546693488536284,\n",
       "   0.034825923778783636,\n",
       "   0.03439087617208662,\n",
       "   0.03390229080596467,\n",
       "   0.03355146819473152,\n",
       "   0.03323035222499648,\n",
       "   0.032987592186864534,\n",
       "   0.0327529095689697,\n",
       "   0.03243658390572614,\n",
       "   0.03225343490062315,\n",
       "   0.03203231202024023,\n",
       "   0.03183789603898059,\n",
       "   0.03164637626370277,\n",
       "   0.03151149436821947,\n",
       "   0.03136512851509292,\n",
       "   0.03124549047892813,\n",
       "   0.031088210394620286,\n",
       "   0.030955416767302988,\n",
       "   0.03086128319039598,\n",
       "   0.03079201836767785,\n",
       "   0.03065874380395388,\n",
       "   0.030547919966604397,\n",
       "   0.03044948770957606,\n",
       "   0.030426024378317852,\n",
       "   0.03033705177190511,\n",
       "   0.030187684821103084,\n",
       "   0.030145063303182344,\n",
       "   0.030106046927802246,\n",
       "   0.030082837576070404,\n",
       "   0.029941818167162522,\n",
       "   0.029943410974100727,\n",
       "   0.029808197344374628,\n",
       "   0.029777315542902177,\n",
       "   0.029740100759831842],\n",
       "  'model_val_losses': [0.03558449610877948,\n",
       "   0.03123578635655391,\n",
       "   0.029088000962688664,\n",
       "   0.027858039198122967,\n",
       "   0.027129385122068368,\n",
       "   0.026216425381268664,\n",
       "   0.02556210699354767,\n",
       "   0.025170504406189464,\n",
       "   0.024659819853533604,\n",
       "   0.024122224895247988,\n",
       "   0.023748647053815,\n",
       "   0.02338683612312481,\n",
       "   0.023157465206399844,\n",
       "   0.02293223403631502,\n",
       "   0.022876325069339412,\n",
       "   0.022563756152892567,\n",
       "   0.022852873061872593,\n",
       "   0.022425392690073154,\n",
       "   0.022227066100403002,\n",
       "   0.021980600253601743,\n",
       "   0.022017563390693846,\n",
       "   0.021791042724422588,\n",
       "   0.021610107842334518,\n",
       "   0.0218378922006317,\n",
       "   0.02156037728118289,\n",
       "   0.021582087051052197,\n",
       "   0.02132909551595047,\n",
       "   0.021211105618317416,\n",
       "   0.021390867650888528,\n",
       "   0.021165859796533917,\n",
       "   0.021160507361125794,\n",
       "   0.02107850942689522,\n",
       "   0.021117433170034627,\n",
       "   0.020829414462397812,\n",
       "   0.02095380864420514,\n",
       "   0.02089644664791739,\n",
       "   0.020719086846253676,\n",
       "   0.020729068797200347,\n",
       "   0.02087026318404705,\n",
       "   0.020747361396243617],\n",
       "  'classifier_train_accuracies': [92.05,\n",
       "   96.226,\n",
       "   97.126,\n",
       "   97.714,\n",
       "   97.972,\n",
       "   98.198,\n",
       "   98.504,\n",
       "   98.438,\n",
       "   98.502,\n",
       "   98.716,\n",
       "   99.134,\n",
       "   99.372,\n",
       "   99.434,\n",
       "   99.5,\n",
       "   99.568,\n",
       "   99.584,\n",
       "   99.626,\n",
       "   99.662,\n",
       "   99.63,\n",
       "   99.72,\n",
       "   99.736,\n",
       "   99.676,\n",
       "   99.726,\n",
       "   99.77,\n",
       "   99.746,\n",
       "   99.802,\n",
       "   99.758,\n",
       "   99.758,\n",
       "   99.75,\n",
       "   99.808],\n",
       "  'classifier_val_accuracies': [96.33,\n",
       "   97.04,\n",
       "   97.23,\n",
       "   97.38,\n",
       "   97.57,\n",
       "   97.94,\n",
       "   97.73,\n",
       "   97.97,\n",
       "   97.82,\n",
       "   97.78,\n",
       "   98.23,\n",
       "   98.2,\n",
       "   98.19,\n",
       "   98.23,\n",
       "   98.29,\n",
       "   98.39,\n",
       "   98.43,\n",
       "   98.32,\n",
       "   98.36,\n",
       "   98.41,\n",
       "   98.34,\n",
       "   98.4,\n",
       "   98.39,\n",
       "   98.4,\n",
       "   98.41,\n",
       "   98.36,\n",
       "   98.37,\n",
       "   98.43,\n",
       "   98.43,\n",
       "   98.38]},\n",
       " 'part_1_cifar': {'model_train_losses': [0.17740352454185485,\n",
       "   0.13244020128250122,\n",
       "   0.1197876958489418,\n",
       "   0.11298433418273926,\n",
       "   0.10876138379573821,\n",
       "   0.10499891866445542,\n",
       "   0.10303312027454377,\n",
       "   0.1016581695318222,\n",
       "   0.10059992536306381,\n",
       "   0.09957215000391006,\n",
       "   0.09887459774017333,\n",
       "   0.09841196411848069,\n",
       "   0.09816736155748368,\n",
       "   0.09732795300483704,\n",
       "   0.09683285553455352,\n",
       "   0.09700047965049743,\n",
       "   0.09645716865062713,\n",
       "   0.09603496867418289,\n",
       "   0.09587461358308792,\n",
       "   0.09565928741693497,\n",
       "   0.09515654177665711,\n",
       "   0.09511543382406235,\n",
       "   0.09479969532489776,\n",
       "   0.09454393022060394,\n",
       "   0.09444546228647233,\n",
       "   0.0939933093547821,\n",
       "   0.09399651049375535,\n",
       "   0.09392341941595078,\n",
       "   0.0938603890657425,\n",
       "   0.09362790405750275,\n",
       "   0.09331601699590683,\n",
       "   0.09121384118795395,\n",
       "   0.09108966788053513,\n",
       "   0.09106679663658142,\n",
       "   0.09095024290084838,\n",
       "   0.09086782867908477,\n",
       "   0.0908509309053421,\n",
       "   0.09105320296287536,\n",
       "   0.09080671344995499,\n",
       "   0.09078319392204284],\n",
       "  'model_val_losses': [0.13968869778001383,\n",
       "   0.12371518424931605,\n",
       "   0.1128770031367138,\n",
       "   0.10885506279908927,\n",
       "   0.1041558225917968,\n",
       "   0.09967510136449413,\n",
       "   0.09951994943011339,\n",
       "   0.09766906476134707,\n",
       "   0.09710286780717267,\n",
       "   0.09642248211582755,\n",
       "   0.09578759598124559,\n",
       "   0.09656975764757508,\n",
       "   0.09618527845592256,\n",
       "   0.09623194713691238,\n",
       "   0.09565597212618324,\n",
       "   0.09522428876085645,\n",
       "   0.09414553087038599,\n",
       "   0.09397484010951535,\n",
       "   0.09404949791681995,\n",
       "   0.09478288143873215,\n",
       "   0.0945212042350678,\n",
       "   0.0948898028226415,\n",
       "   0.09324633852121936,\n",
       "   0.09374482516840005,\n",
       "   0.09281707379468687,\n",
       "   0.09345087769684518,\n",
       "   0.09352274011274811,\n",
       "   0.09329441697544354,\n",
       "   0.09373934154108071,\n",
       "   0.09291375328780739,\n",
       "   0.09290945548920115,\n",
       "   0.09118432798393213,\n",
       "   0.09118713623589011,\n",
       "   0.09112759461258627,\n",
       "   0.09107430004010535,\n",
       "   0.09115878578014434,\n",
       "   0.0912744451290483,\n",
       "   0.09131243549714423,\n",
       "   0.09122768186839522,\n",
       "   0.09115216221399368],\n",
       "  'classifier_train_accuracies': [41.1875,\n",
       "   48.8175,\n",
       "   51.865,\n",
       "   54.3875,\n",
       "   56.155,\n",
       "   57.7025,\n",
       "   58.54,\n",
       "   60.2775,\n",
       "   60.74,\n",
       "   61.6925,\n",
       "   65.48,\n",
       "   66.7375,\n",
       "   67.85,\n",
       "   67.8175,\n",
       "   68.4225,\n",
       "   68.805,\n",
       "   69.06,\n",
       "   69.11,\n",
       "   69.325,\n",
       "   70.025,\n",
       "   70.64,\n",
       "   70.5425,\n",
       "   70.8275,\n",
       "   70.85,\n",
       "   70.7875,\n",
       "   70.6375,\n",
       "   71.2,\n",
       "   71.18,\n",
       "   71.22,\n",
       "   71.03],\n",
       "  'classifier_val_accuracies': [49.82,\n",
       "   52.32,\n",
       "   54.13,\n",
       "   54.72,\n",
       "   56.11,\n",
       "   56.71,\n",
       "   56.71,\n",
       "   56.39,\n",
       "   57.34,\n",
       "   57.83,\n",
       "   59.0,\n",
       "   59.78,\n",
       "   59.13,\n",
       "   58.97,\n",
       "   59.11,\n",
       "   59.53,\n",
       "   59.22,\n",
       "   59.26,\n",
       "   59.58,\n",
       "   59.65,\n",
       "   59.66,\n",
       "   59.54,\n",
       "   59.67,\n",
       "   59.51,\n",
       "   59.73,\n",
       "   59.48,\n",
       "   59.57,\n",
       "   59.81,\n",
       "   59.74,\n",
       "   59.63]},\n",
       " 'part_2_mnist': {'model_train_losses': None,\n",
       "  'model_val_losses': None,\n",
       "  'classifier_train_accuracies': [95.462,\n",
       "   97.954,\n",
       "   98.328,\n",
       "   98.732,\n",
       "   98.878,\n",
       "   99.042,\n",
       "   99.23,\n",
       "   99.24,\n",
       "   99.336,\n",
       "   99.378,\n",
       "   99.5,\n",
       "   99.466,\n",
       "   99.772,\n",
       "   99.874,\n",
       "   99.93,\n",
       "   99.946,\n",
       "   99.952,\n",
       "   99.976,\n",
       "   99.974,\n",
       "   99.982,\n",
       "   99.984,\n",
       "   99.986,\n",
       "   99.982,\n",
       "   99.98,\n",
       "   99.988,\n",
       "   99.992,\n",
       "   99.984,\n",
       "   99.994,\n",
       "   99.992,\n",
       "   99.988,\n",
       "   99.986,\n",
       "   99.992,\n",
       "   99.984,\n",
       "   99.992,\n",
       "   99.986,\n",
       "   99.98,\n",
       "   99.99,\n",
       "   99.992,\n",
       "   99.992,\n",
       "   99.982],\n",
       "  'classifier_val_accuracies': [97.78,\n",
       "   98.28,\n",
       "   98.28,\n",
       "   98.45,\n",
       "   98.23,\n",
       "   98.6,\n",
       "   98.55,\n",
       "   98.54,\n",
       "   98.58,\n",
       "   98.23,\n",
       "   98.57,\n",
       "   98.66,\n",
       "   98.87,\n",
       "   98.91,\n",
       "   98.93,\n",
       "   98.9,\n",
       "   98.92,\n",
       "   98.93,\n",
       "   98.93,\n",
       "   98.94,\n",
       "   98.96,\n",
       "   98.93,\n",
       "   98.96,\n",
       "   98.94,\n",
       "   98.93,\n",
       "   98.92,\n",
       "   98.92,\n",
       "   98.95,\n",
       "   98.9,\n",
       "   98.96,\n",
       "   98.92,\n",
       "   98.93,\n",
       "   98.96,\n",
       "   98.93,\n",
       "   98.95,\n",
       "   98.89,\n",
       "   98.93,\n",
       "   98.94,\n",
       "   98.97,\n",
       "   98.9]},\n",
       " 'part_2_cifar': {'model_train_losses': None,\n",
       "  'model_val_losses': None,\n",
       "  'classifier_train_accuracies': [47.5825,\n",
       "   62.5325,\n",
       "   69.3625,\n",
       "   74.4375,\n",
       "   78.965,\n",
       "   82.7425,\n",
       "   85.675,\n",
       "   88.3025,\n",
       "   90.235,\n",
       "   91.6775,\n",
       "   93.1375,\n",
       "   93.96,\n",
       "   97.205,\n",
       "   98.605,\n",
       "   99.07,\n",
       "   99.3775,\n",
       "   99.5,\n",
       "   99.605,\n",
       "   99.665,\n",
       "   99.6675,\n",
       "   99.7975,\n",
       "   99.825,\n",
       "   99.8525,\n",
       "   99.8375,\n",
       "   99.835,\n",
       "   99.8525,\n",
       "   99.8675,\n",
       "   99.885,\n",
       "   99.8775,\n",
       "   99.87,\n",
       "   99.8675,\n",
       "   99.9,\n",
       "   99.885,\n",
       "   99.87,\n",
       "   99.85,\n",
       "   99.8975,\n",
       "   99.91,\n",
       "   99.9025,\n",
       "   99.89,\n",
       "   99.89],\n",
       "  'classifier_val_accuracies': [56.82,\n",
       "   64.9,\n",
       "   67.31,\n",
       "   68.31,\n",
       "   69.17,\n",
       "   69.24,\n",
       "   68.96,\n",
       "   69.07,\n",
       "   67.93,\n",
       "   67.23,\n",
       "   67.79,\n",
       "   67.92,\n",
       "   69.19,\n",
       "   69.4,\n",
       "   69.08,\n",
       "   69.06,\n",
       "   68.74,\n",
       "   68.86,\n",
       "   68.77,\n",
       "   68.88,\n",
       "   68.83,\n",
       "   68.96,\n",
       "   68.83,\n",
       "   69.27,\n",
       "   68.95,\n",
       "   69.29,\n",
       "   68.91,\n",
       "   69.05,\n",
       "   68.92,\n",
       "   69.0,\n",
       "   69.06,\n",
       "   69.01,\n",
       "   68.98,\n",
       "   68.81,\n",
       "   69.01,\n",
       "   68.88,\n",
       "   69.06,\n",
       "   69.06,\n",
       "   68.86,\n",
       "   68.91]},\n",
       " 'part_3_mnist': {'model_train_losses': [4.8121737022789155,\n",
       "   3.3808526560968284,\n",
       "   2.7354086874699104,\n",
       "   2.272109610541743,\n",
       "   1.8817556999167617,\n",
       "   1.8299669516938073,\n",
       "   1.6670329920491394,\n",
       "   1.6147447675466537,\n",
       "   1.5385436756270272,\n",
       "   1.345768266794633,\n",
       "   1.3249592963530092,\n",
       "   1.2352188960934172,\n",
       "   1.3067264897482735,\n",
       "   1.2269162097755744,\n",
       "   1.1728766619855044,\n",
       "   1.1454170939265464,\n",
       "   1.127513369887459,\n",
       "   1.0561605448625526,\n",
       "   1.0835127214692077,\n",
       "   1.061895755784852,\n",
       "   1.0303358535985558,\n",
       "   1.0248147646079258,\n",
       "   1.0212003859330196,\n",
       "   0.9339126111293325,\n",
       "   0.8828335783007194,\n",
       "   0.8640416852977811,\n",
       "   0.8779775931366852,\n",
       "   0.9018753513085599,\n",
       "   0.8513712606259755,\n",
       "   0.9184390072311673,\n",
       "   0.8041496202349663,\n",
       "   0.863071548923546,\n",
       "   0.8689349406988037,\n",
       "   0.8592071504313119,\n",
       "   0.8109143592265188,\n",
       "   0.8839810822083025,\n",
       "   0.8282233829400978,\n",
       "   0.8791049767513665,\n",
       "   0.8564982900053871,\n",
       "   0.7373164068831473],\n",
       "  'model_val_losses': [2.190221954882145,\n",
       "   1.7675875753164292,\n",
       "   1.3195057198405267,\n",
       "   0.8855871528387069,\n",
       "   0.8951027989387512,\n",
       "   0.7974986732006073,\n",
       "   0.6863039672374726,\n",
       "   0.5772629871964454,\n",
       "   0.5081850625574589,\n",
       "   0.5394698828458786,\n",
       "   0.44125659167766573,\n",
       "   0.41418831795454025,\n",
       "   0.40587408021092414,\n",
       "   0.4166268229484558,\n",
       "   0.40089416280388834,\n",
       "   0.40835655853152275,\n",
       "   0.36509771198034285,\n",
       "   0.3665834844112396,\n",
       "   0.36833843067288397,\n",
       "   0.37953181341290476,\n",
       "   0.37531693354249,\n",
       "   0.31824027225375173,\n",
       "   0.2937432684004307,\n",
       "   0.3192262418568134,\n",
       "   0.29047242775559423,\n",
       "   0.28680372759699824,\n",
       "   0.33149234429001806,\n",
       "   0.29631884172558787,\n",
       "   0.2976120002567768,\n",
       "   0.3131093576550484,\n",
       "   0.3038610741496086,\n",
       "   0.2636346098035574,\n",
       "   0.24683681465685367,\n",
       "   0.29579159393906596,\n",
       "   0.3438433326780796,\n",
       "   0.25209992080926896,\n",
       "   0.3831537887454033,\n",
       "   0.2684432610869408,\n",
       "   0.22265608571469783,\n",
       "   0.24721357971429825],\n",
       "  'classifier_train_accuracies': [91.97,\n",
       "   95.572,\n",
       "   96.332,\n",
       "   96.654,\n",
       "   96.926,\n",
       "   97.182,\n",
       "   97.366,\n",
       "   97.468,\n",
       "   97.496,\n",
       "   97.6,\n",
       "   98.236,\n",
       "   98.516,\n",
       "   98.598,\n",
       "   98.73,\n",
       "   98.73,\n",
       "   98.796,\n",
       "   98.84,\n",
       "   98.884,\n",
       "   98.938,\n",
       "   99.038,\n",
       "   99.082,\n",
       "   99.046,\n",
       "   99.054,\n",
       "   99.134,\n",
       "   99.174,\n",
       "   99.152,\n",
       "   99.166,\n",
       "   99.096,\n",
       "   99.12,\n",
       "   99.158],\n",
       "  'classifier_val_accuracies': [95.68,\n",
       "   96.85,\n",
       "   97.04,\n",
       "   96.81,\n",
       "   97.48,\n",
       "   97.23,\n",
       "   97.88,\n",
       "   97.97,\n",
       "   97.7,\n",
       "   97.91,\n",
       "   98.26,\n",
       "   98.29,\n",
       "   98.39,\n",
       "   98.36,\n",
       "   98.39,\n",
       "   98.41,\n",
       "   98.39,\n",
       "   98.44,\n",
       "   98.46,\n",
       "   98.48,\n",
       "   98.48,\n",
       "   98.54,\n",
       "   98.53,\n",
       "   98.58,\n",
       "   98.5,\n",
       "   98.5,\n",
       "   98.53,\n",
       "   98.54,\n",
       "   98.53,\n",
       "   98.48]},\n",
       " 'part_3_cifar': {'model_train_losses': [2.365343608294323,\n",
       "   1.5437823511232995,\n",
       "   1.4323261232133124,\n",
       "   1.1921411948219227,\n",
       "   1.0113659293218782,\n",
       "   1.075179096145235,\n",
       "   0.8564737318617524,\n",
       "   0.8035451001042773,\n",
       "   0.707941216363269,\n",
       "   0.8027305911490872,\n",
       "   0.7567589930288351,\n",
       "   0.6935787958324335,\n",
       "   0.6631654375677656,\n",
       "   0.7428689072276377,\n",
       "   0.6380333786557435,\n",
       "   0.6001959300250005,\n",
       "   0.5567732646491876,\n",
       "   0.5896856390936359,\n",
       "   0.6203044620668812,\n",
       "   0.5848769386103199,\n",
       "   0.5027334076014294,\n",
       "   0.5769966995924901,\n",
       "   0.5577077886955754,\n",
       "   0.5120328162695952,\n",
       "   0.48386015828437867,\n",
       "   0.5138642367473834,\n",
       "   0.4964578231428839,\n",
       "   0.47445731690734816,\n",
       "   0.43457863859500095,\n",
       "   0.4538582014335189,\n",
       "   0.4252207831355037,\n",
       "   0.4628730664017853,\n",
       "   0.4574846656648976,\n",
       "   0.42305295648658353,\n",
       "   0.35253657571449404,\n",
       "   0.40174032187765574,\n",
       "   0.3878827142487666,\n",
       "   0.410021701388678,\n",
       "   0.3955616013734204,\n",
       "   0.386061235265747,\n",
       "   0.43037850348053464,\n",
       "   0.40686311658210816,\n",
       "   0.3546822152936914,\n",
       "   0.3905288378239437,\n",
       "   0.363807004111208,\n",
       "   0.36487103225129425,\n",
       "   0.40520321539822657,\n",
       "   0.3744475804981153,\n",
       "   0.3536289087051799,\n",
       "   0.34545509128054236,\n",
       "   0.36123291512203826,\n",
       "   0.3505244797012608,\n",
       "   0.38117728154560565,\n",
       "   0.37727408132450596,\n",
       "   0.3773065537309191,\n",
       "   0.3721325000285343,\n",
       "   0.36757067367909063,\n",
       "   0.32418710586561517,\n",
       "   0.40938312759634793,\n",
       "   0.34064305962840463],\n",
       "  'model_val_losses': [0.38747755736112593,\n",
       "   0.2819110661745071,\n",
       "   0.35330523550510406,\n",
       "   0.21289955601096153,\n",
       "   0.21370835043489933,\n",
       "   0.15579268671572208,\n",
       "   0.1633351068943739,\n",
       "   0.14218840859830378,\n",
       "   0.15777409374713897,\n",
       "   0.2217874076217413,\n",
       "   0.12324697431176901,\n",
       "   0.12110214605927468,\n",
       "   0.16536351963877677,\n",
       "   0.1263648422434926,\n",
       "   0.15596802309155464,\n",
       "   0.11348946001380682,\n",
       "   0.1272588972002268,\n",
       "   0.1112710976973176,\n",
       "   0.14379102401435376,\n",
       "   0.13763263039290904,\n",
       "   0.10418720580637456,\n",
       "   0.10268216878175736,\n",
       "   0.15671720094978808,\n",
       "   0.09896131791174412,\n",
       "   0.097261998988688,\n",
       "   0.10885018110275269,\n",
       "   0.12163627743721009,\n",
       "   0.08745573814958334,\n",
       "   0.09662667326629162,\n",
       "   0.0936199240386486,\n",
       "   0.09880010858178138,\n",
       "   0.09879302997142077,\n",
       "   0.0925042487680912,\n",
       "   0.11702344063669443,\n",
       "   0.08035304863005877,\n",
       "   0.08325693476945162,\n",
       "   0.08293649684637786,\n",
       "   0.07894892729818821,\n",
       "   0.08047446515411139,\n",
       "   0.08242308199405671,\n",
       "   0.08131694681942463,\n",
       "   0.0794422859326005,\n",
       "   0.07917893622070551,\n",
       "   0.08201653454452754,\n",
       "   0.07883953712880612,\n",
       "   0.07789660803973675,\n",
       "   0.08071680217981339,\n",
       "   0.07859640046954156,\n",
       "   0.07722807824611663,\n",
       "   0.0774113105610013,\n",
       "   0.07685124222189188,\n",
       "   0.07827691547572613,\n",
       "   0.07722009718418121,\n",
       "   0.07760880403220653,\n",
       "   0.07739613931626081,\n",
       "   0.07803059946745634,\n",
       "   0.07779471315443516,\n",
       "   0.07730499729514122,\n",
       "   0.07813594546169042,\n",
       "   0.07698948830366134],\n",
       "  'classifier_train_accuracies': [53.1375,\n",
       "   59.2175,\n",
       "   61.0675,\n",
       "   62.3775,\n",
       "   63.61,\n",
       "   64.3375,\n",
       "   64.86,\n",
       "   65.5325,\n",
       "   66.0525,\n",
       "   66.73,\n",
       "   68.7475,\n",
       "   69.7825,\n",
       "   69.9375,\n",
       "   70.76,\n",
       "   70.4575,\n",
       "   71.0175,\n",
       "   70.7175,\n",
       "   71.3725,\n",
       "   71.455,\n",
       "   71.5975,\n",
       "   71.9675,\n",
       "   71.885,\n",
       "   72.0525,\n",
       "   72.26,\n",
       "   72.065,\n",
       "   72.2925,\n",
       "   72.0225,\n",
       "   72.4925,\n",
       "   72.595,\n",
       "   72.0875,\n",
       "   72.4975,\n",
       "   72.19,\n",
       "   72.5275,\n",
       "   72.4475,\n",
       "   72.59,\n",
       "   72.3075,\n",
       "   72.2425,\n",
       "   72.57,\n",
       "   72.5725,\n",
       "   72.4],\n",
       "  'classifier_val_accuracies': [60.59,\n",
       "   62.17,\n",
       "   63.38,\n",
       "   63.91,\n",
       "   64.81,\n",
       "   65.31,\n",
       "   65.15,\n",
       "   66.13,\n",
       "   65.97,\n",
       "   66.27,\n",
       "   66.95,\n",
       "   67.05,\n",
       "   67.2,\n",
       "   67.4,\n",
       "   67.62,\n",
       "   67.49,\n",
       "   67.56,\n",
       "   67.72,\n",
       "   67.88,\n",
       "   67.69,\n",
       "   67.81,\n",
       "   67.8,\n",
       "   67.91,\n",
       "   67.93,\n",
       "   68.08,\n",
       "   67.84,\n",
       "   67.91,\n",
       "   67.83,\n",
       "   67.96,\n",
       "   67.96,\n",
       "   67.81,\n",
       "   67.93,\n",
       "   67.94,\n",
       "   67.91,\n",
       "   68.04,\n",
       "   68.02,\n",
       "   67.89,\n",
       "   68.05,\n",
       "   67.95,\n",
       "   67.91]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0416e82f-4e44-470a-86e6-1d2ee34916db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
